qplot(fixed.acidity, pH, data=wine, color=factor(clust1$cluster))
clust1$center
library(ClusterR)
clust2 = KMeans_rcpp(X, clusters=2, num_init=25, initializer = 'kmeans++')
clust2$center
clust2 = KMeans_rcpp(X, clusters=2, num_init=25, initializer = 'kmeans++')
clust2$total_SSE
clust1$totss
View(wine)
Z = wine[,c(1,4)]
View(Z)
Z = wine[,c(1:11)]
View(Z)
Z = wine[,c(1:11)]
Z = wine(Z, center=TRUE, scale=FALSE)
Z = wine[,c(1:11)]
Z = scale(Z, center=TRUE, scale=FALSE)
plot(Z)
Z = wine[,c(1:11)]
Z = scale(Z, center=TRUE, scale=FALSE)
v_try = rnorm(2)
v_try = v_try/sqrt(sum(v_try^2))
plot(Z, pch=19, col=rgb(0.3,0.3,0.3,0.3))
segments(0, 0, v_try[1], v_try[2], col='red', lwd=4)
Z = wine[,c(1:11)]
Z = scale(Z, center=TRUE, scale=FALSE)
v_try = rnorm(2)
v_try = v_try/sqrt(sum(v_try^2))
plot(Z, pch=19, col=rgb(0.3,0.3,0.3,0.3))
segments(0, 0, v_try[1], v_try[2], col='red', lwd=4)
slope = v_try[2]/v_try[1]
abline(0, slope)
Z = wine[,c(1:11)]
Z = scale(Z, center=TRUE, scale=FALSE)
v_try = rnorm(2)
v_try = v_try/sqrt(sum(v_try^2))
par(mfrow=c(1,2))
plot(Z, pch=19, col=rgb(0.3,0.3,0.3,0.3),
xlim=c(-2.5,2.5), ylim=c(-2.5,2.5))
slope = v_try[2]/v_try[1]
abline(0, slope)  # plot the subspace as a line
# Project the points onto that subspace
alpha = Z %*% v_try  # inner product of each row with v_try
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
pca_result$rotation
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
pca_result$rotation
pca_result$x
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
summary(pca_result)
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
pca_result$rotation
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
temp = prcomp(wine[,1:11], center = TRUE, scale. = TRUE, rank=8)
summary(temp)
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
pca_result$rotation
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
# Perform k-means clustering on the PCA-transformed data (first 8 principal components)
set.seed(123)  # Set seed for reproducibility
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:8]
# Perform k-means clustering on the PCA-transformed data (first 8 principal components)
set.seed(123)  # Set seed for reproducibility
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
# View the cluster assignments
kmeans_result$cluster
# Add the cluster assignments to the PCA data for easier visualization
pca_df = data.frame(PC1 = pca_data[, 1], PC2 = pca_data[, 2], Cluster = as.factor(kmeans_result$cluster))
# Visualize the clusters using the first two principal components
library(ggplot2)
ggplot(pca_df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
labs(title = "K-means Clustering on PCA-Transformed Data (First 2 PCs)")
# Perform k-means clustering on the PCA-transformed data (first 8 principal components)
set.seed(123)  # Set seed for reproducibility
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
# Add the cluster assignments to the PCA data for easier visualization
pca_df = data.frame(PC1 = pca_data[, 1], PC2 = pca_data[, 2], Cluster = as.factor(kmeans_result$cluster))
# Visualize the clusters using the first two principal components
library(ggplot2)
ggplot(pca_df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
labs(title = "K-means Clustering on PCA-Transformed Data (First 2 PCs)")
View(pca_df)
# Perform k-means clustering on the PCA-transformed data (first 8 principal components)
set.seed(123)  # Set seed for reproducibility
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
# Add the k-means cluster assignments to the original wine data
wine$kmeans_cluster = kmeans_result$cluster
# Assuming the actual clusters are in a column named 'actual_cluster'
table(wine$actual_cluster, wine$kmeans_cluster)
wine <- read_csv("wine.csv") %>%
mutate(color_num = ifelse(color == "red", 1, 2))
# Perform k-means clustering on the PCA-transformed data (first 8 principal components)
set.seed(123)  # Set seed for reproducibility
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
# Add the k-means cluster assignments to the original wine data
wine$kmeans_cluster = kmeans_result$cluster
# Assuming the actual clusters are in a column named 'actual_cluster'
table(wine$color_num, wine$kmeans_cluster)
# Optionally, calculate the accuracy
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
# Compute the distance matrix using Euclidean distance
distance_matrix = dist(pca_data)
# Perform hierarchical clustering using the average linkage method
hc = hclust(distance_matrix, method = "average")
# Plot the dendrogram
plot(hc, main = "Dendrogram of Hierarchical Clustering", xlab = "", sub = "", cex = 0.9)
# Cut the dendrogram to form 2 clusters
hc_clusters = cutree(hc, k = 2)
# Add the hierarchical cluster assignments to the original wine data
wine$hc_cluster = hc_clusters
# Compare hierarchical clustering assignments with actual clusters
table(wine$color_num, wine$hc_cluster)
# Calculate accuracy (if applicable)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
install.packages("kernlab")
library(kernlab)
spectral_result = specc(pca_data, centers = 2)
spectral_result = specc(pca_data, centers = 2)
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:11]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:5]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:8]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
View(wine)
wine <- read_csv("wine.csv") %>%
mutate(color_num = ifelse(color == "red", 1, 2)) %>%
select(-free.sulfur.dioxide)
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:8]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
wine <- read_csv("wine.csv") %>%
mutate(color_num = ifelse(color == "red", 1, 2))
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:3]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:3]
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:6]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), type='b',
xlab='Number of Principal Components', ylab='Cumulative Proportion of Variance Explained',
main='PCA: Cumulative Proportion of Variance Explained')
#Chose to use 8 PCs because >90% variance explained
pca_data = pca_result$x[, 1:6]
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
#Chose to use 7 PCs because proportion of variance explained begins to flatten
pca_data = pca_result$x[, 1:7]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 10, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality, wine$kmeans_cluster)
accuracy = sum(wine$quality == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 10, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality, wine$kmeans_cluster)
accuracy = sum(wine$quality == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 10, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality, wine$kmeans_cluster)
accuracy = sum(wine$quality == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 10)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality, wine$hc_cluster)
hc_accuracy = sum(wine$quality == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 10)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality, wine$hc_cluster)
hc_accuracy = sum(wine$quality == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
wine <- read_csv("wine.csv") %>%
mutate(color_num = ifelse(color == "red", 2, 1))
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
#Chose to use 7 PCs because proportion of variance explained begins to flatten
pca_data = pca_result$x[, 1:7]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 10, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality, wine$kmeans_cluster)
accuracy = sum(wine$quality == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 10)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality, wine$hc_cluster)
hc_accuracy = sum(wine$quality == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
# Calculate the mean quality for each cluster
cluster_means = aggregate(wine$quality, by = list(kmeans_cluster = wine$kmeans_cluster), FUN = mean)
colnames(cluster_means)[2] = "mean_quality"
# Sort clusters by mean quality to match rank with quality
cluster_means = cluster_means[order(cluster_means$mean_quality), ]
# Create a mapping from cluster number to quality rank
cluster_map = setNames(1:10, cluster_means$kmeans_cluster)
# Apply the mapping to the cluster assignments
wine$ranked_cluster = cluster_map[wine$kmeans_cluster]
# Compare the ranked clusters with the actual quality
table(wine$quality, wine$ranked_cluster)
# Calculate accuracy
accuracy = sum(wine$quality == wine$ranked_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
# Step 3: Calculate the Average Quality for Each Cluster
cluster_means = aggregate(wine$quality, by = list(wine$hc_cluster), FUN = mean)
colnames(cluster_means) = c("Cluster", "Avg_Quality")
# Step 4: Order Clusters by Average Quality and Assign Ranks
cluster_means = cluster_means[order(cluster_means$Avg_Quality), ]
cluster_means$Rank = 1:nrow(cluster_means)
# Step 5: Create a Mapping from Original Cluster Number to Rank-Based Cluster Number
cluster_mapping = setNames(cluster_means$Rank, cluster_means$Cluster)
# Step 6: Reassign Cluster Numbers Based on Rank
wine$ranked_cluster = cluster_mapping[wine$hc_cluster]
# Step 7: Compare Ranked Clusters with Actual Quality
table(wine$quality, wine$ranked_cluster)
# Optionally, Calculate Accuracy
ranked_accuracy = sum(wine$quality == wine$ranked_cluster) / nrow(wine)
print(paste("Ranked Hierarchical Clustering Accuracy:", round(ranked_accuracy * 100, 2), "%"))
wine <- read_csv("wine.csv") %>%
mutate(color_num = ifelse(color == "white", 1, 2))
pca_result = prcomp(wine[,1:11], center = TRUE, scale. = TRUE)
summary(pca_result)
#Chose to use 7 PCs because proportion of variance explained begins to flatten
pca_data = pca_result$x[, 1:7]
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 2, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$color_num, wine$kmeans_cluster)
accuracy = sum(wine$color_num == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 2)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$color_num, wine$hc_cluster)
hc_accuracy = sum(wine$color_num == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 10, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality, wine$kmeans_cluster)
accuracy = sum(wine$quality == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 10)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality, wine$hc_cluster)
hc_accuracy = sum(wine$quality == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
summary(wine$quality)
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 7, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality, wine$kmeans_cluster)
accuracy = sum(wine$quality == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 7)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality, wine$hc_cluster)
hc_accuracy = sum(wine$quality == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
#find how many clusters
summary(wine$quality)
#adjust quality vals to match cluster assignments
wine <- wine %>%
mutate(quality_edit = quality - 3)
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 7, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality_edit, wine$kmeans_cluster)
accuracy = sum(wine$quality_edit == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 7)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality_edit, wine$hc_cluster)
hc_accuracy = sum(wine$quality_edit == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
#find how many clusters
summary(wine$quality)
#adjust quality vals to match cluster assignments
wine <- wine %>%
mutate(quality_edit = quality - 2)
set.seed(123)
kmeans_result = kmeans(pca_data, centers = 7, nstart = 25)
#FInd Accuracy:
wine$kmeans_cluster = kmeans_result$cluster
table(wine$quality_edit, wine$kmeans_cluster)
accuracy = sum(wine$quality_edit == wine$kmeans_cluster) / nrow(wine)
print(paste("Clustering Accuracy:", round(accuracy * 100, 2), "%"))
distance_matrix = dist(pca_data)
hc = hclust(distance_matrix, method = "average")
hc_clusters = cutree(hc, k = 7)
#Find Accuracy:
wine$hc_cluster = hc_clusters
table(wine$quality_edit, wine$hc_cluster)
hc_accuracy = sum(wine$quality_edit == wine$hc_cluster) / nrow(wine)
print(paste("Hierarchical Clustering Accuracy:", round(hc_accuracy * 100, 2), "%"))
